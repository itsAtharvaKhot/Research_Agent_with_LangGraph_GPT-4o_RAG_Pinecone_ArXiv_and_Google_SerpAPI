{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b4046103-9014-4dc1-970b-95ebdab09c8e",
      "metadata": {
        "id": "b4046103-9014-4dc1-970b-95ebdab09c8e"
      },
      "outputs": [],
      "source": [
        "pip install -r requirements.txt -q"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1369622e-9c8a-4574-be95-d053ad2be0cd",
      "metadata": {
        "id": "1369622e-9c8a-4574-be95-d053ad2be0cd"
      },
      "outputs": [],
      "source": [
        "import requests\n",
        "import pandas as pd\n",
        "import json\n",
        "import xml.etree.ElementTree as ET\n",
        "\n",
        "ARXIV_NAMESPACE = '{http://www.w3.org/2005/Atom}'\n",
        "\n",
        "def extract_from_arxiv(search_query='cat:cs.AI', max_results=100, json_file_path='files/arxiv_dataset.json'):\n",
        "    \"\"\"\n",
        "    Fetches papers from the ArXiv API based on a search query, saves them as JSON,\n",
        "    and returns a pandas DataFrame.\n",
        "\n",
        "    Args:\n",
        "        search_query (str): The search query for ArXiv (default is 'cat:cs.AI').\n",
        "        max_results (int): The maximum number of results to retrieve (default is 100).\n",
        "        json_file_path (str): File path where JSON data will be saved.\n",
        "\n",
        "    Returns:\n",
        "        pd.DataFrame: DataFrame containing the extracted paper information.\n",
        "    \"\"\"\n",
        "\n",
        "    url = f'http://export.arxiv.org/api/query?search_query={search_query}&max_results={max_results}'\n",
        "    response = requests.get(url)\n",
        "    root = ET.fromstring(response.content)\n",
        "\n",
        "    papers = []\n",
        "\n",
        "    # Loop through each \"entry\" in the XML, representing a single paper.\n",
        "    for entry in root.findall(f'{ARXIV_NAMESPACE}entry'):\n",
        "        title = entry.find(f'{ARXIV_NAMESPACE}title').text.strip()\n",
        "        summary = entry.find(f'{ARXIV_NAMESPACE}summary').text.strip()\n",
        "\n",
        "        author_elements = entry.findall(f'{ARXIV_NAMESPACE}author')\n",
        "        authors = [author.find(f'{ARXIV_NAMESPACE}name').text for author in author_elements]\n",
        "        paper_url = entry.find(f'{ARXIV_NAMESPACE}id').text\n",
        "        arxiv_id = paper_url.split('/')[-1]\n",
        "        pdf_link = next((link.attrib['href'] for link in entry.findall(f'{ARXIV_NAMESPACE}link')\n",
        "                         if link.attrib.get('title') == 'pdf'), None)\n",
        "\n",
        "        papers.append({\n",
        "            'title': title,\n",
        "            'summary': summary,\n",
        "            'authors': authors,\n",
        "            'arxiv_id': arxiv_id,\n",
        "            'url': paper_url,\n",
        "            'pdf_link': pdf_link\n",
        "        })\n",
        "\n",
        "    # Convert list into a pandas DataFrame.\n",
        "    df = pd.DataFrame(papers)\n",
        "\n",
        "    # Save the DataFrame to a JSON file.\n",
        "    with open(json_file_path, 'w', encoding='utf-8') as f:\n",
        "        json.dump(papers, f, ensure_ascii=False, indent=4)\n",
        "        print(f'Data saved to {json_file_path} ...')\n",
        "\n",
        "    return df\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "56d081fa-e45f-4e90-b62e-b27ad71f9626",
      "metadata": {
        "id": "56d081fa-e45f-4e90-b62e-b27ad71f9626"
      },
      "outputs": [],
      "source": [
        "df = extract_from_arxiv(max_results=20)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "78f4006e-99a7-4f3e-a3fd-6e80cce2ae66",
      "metadata": {
        "scrolled": true,
        "id": "78f4006e-99a7-4f3e-a3fd-6e80cce2ae66"
      },
      "outputs": [],
      "source": [
        "import json\n",
        "file_name = 'files/arxiv_dataset.json'\n",
        "with  open(file_name, 'r') as file:\n",
        "    data = json.load(file)\n",
        "\n",
        "print(data)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "362b4cf3-663b-431e-b5ab-23b98ea1a98a",
      "metadata": {
        "id": "362b4cf3-663b-431e-b5ab-23b98ea1a98a"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "df = pd.DataFrame(data)\n",
        "df.sample(n=5)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1ebbd8b0-a9e4-44e3-88be-4dcbf6273a21",
      "metadata": {
        "id": "1ebbd8b0-a9e4-44e3-88be-4dcbf6273a21"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import requests\n",
        "import os\n",
        "\n",
        "def download_pdfs(df, download_folder='files'):\n",
        "    \"\"\"\n",
        "    Downloads PDFs from URLs listed in the DataFrame and saves them to a specified folder.\n",
        "    The file names are stored in a new column 'pdf_file_name' in the DataFrame.\n",
        "\n",
        "    Args:\n",
        "        df (pd.DataFrame): DataFrame containing a 'pdf_link' column with URLs to download.\n",
        "        download_folder (str): Path to the folder where PDFs will be saved (default is 'files').\n",
        "\n",
        "    Returns:\n",
        "        pd.DataFrame: The original DataFrame with an additional 'pdf_file_name' column containing\n",
        "                      the paths of the downloaded PDF files or None if the download failed.\n",
        "    \"\"\"\n",
        "\n",
        "    if not os.path.exists(download_folder):\n",
        "        os.makedirs(download_folder)\n",
        "\n",
        "    pdf_file_names = []\n",
        "\n",
        "    # Loop through each row to download PDFs\n",
        "    for index, row in df.iterrows():\n",
        "        pdf_link = row['pdf_link']\n",
        "\n",
        "        try:\n",
        "            response = requests.get(pdf_link)\n",
        "            response.raise_for_status()\n",
        "\n",
        "            file_name = os.path.join(download_folder, pdf_link.split('/')[-1]) + '.pdf'\n",
        "            pdf_file_names.append(file_name)\n",
        "\n",
        "            with open(file_name, 'wb') as f:\n",
        "                f.write(response.content)\n",
        "\n",
        "            print(f'PDF downloaded successfully and saved as {file_name}')\n",
        "\n",
        "        except requests.exceptions.RequestException as e:\n",
        "            print(f'Failed to download the PDF: {e}')\n",
        "            pdf_file_names.append(None)\n",
        "\n",
        "    df['pdf_file_name'] = pdf_file_names\n",
        "\n",
        "    return df\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e2082ee0-8457-4844-9680-fd92e81dbd8a",
      "metadata": {
        "id": "e2082ee0-8457-4844-9680-fd92e81dbd8a"
      },
      "outputs": [],
      "source": [
        "df = download_pdfs(df)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "81050f98-2aa3-47b5-9e11-048335bef539",
      "metadata": {
        "id": "81050f98-2aa3-47b5-9e11-048335bef539"
      },
      "outputs": [],
      "source": [
        "from langchain.document_loaders import PyPDFLoader\n",
        "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
        "\n",
        "def load_and_chunk_pdf(pdf_file_name, chunk_size=512):\n",
        "    \"\"\"\n",
        "    Loads a PDF file and splits its content into chunks of a specified size.\n",
        "\n",
        "    Args:\n",
        "        file (str): Path to the PDF file to be loaded.\n",
        "        chunk_size (int): The maximum size of each chunk in characters (default is 512).\n",
        "\n",
        "    Returns:\n",
        "        List[Document]: A list of document chunks.\n",
        "    \"\"\"\n",
        "\n",
        "    print(f'Loading and splitting into chunks: {pdf_file_name}')\n",
        "    loader = PyPDFLoader(pdf_file_name)\n",
        "    data = loader.load()\n",
        "\n",
        "    # Split the content into chunks\n",
        "    text_splitter = RecursiveCharacterTextSplitter(chunk_size=chunk_size, chunk_overlap=64)\n",
        "    chunks = text_splitter.split_documents(data)\n",
        "\n",
        "    return chunks\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d1607083-0b0c-45b3-848e-3cd6af2d19e3",
      "metadata": {
        "id": "d1607083-0b0c-45b3-848e-3cd6af2d19e3"
      },
      "outputs": [],
      "source": [
        "def expand_df(df):\n",
        "    \"\"\"\n",
        "    Expands each row in the DataFrame by splitting PDF documents into chunks.\n",
        "\n",
        "    Args:\n",
        "        df (pd.DataFrame): DataFrame containing 'pdf_file_name', 'arxiv_id', 'title', 'summary',\n",
        "                           'authors', and 'url' columns.\n",
        "\n",
        "    Returns:\n",
        "        pd.DataFrame: A new DataFrame where each row represents a chunk of the original document,\n",
        "                      with additional metadata such as chunk identifiers and relationships to\n",
        "                      adjacent chunks.\n",
        "    \"\"\"\n",
        "\n",
        "    expanded_rows = []\n",
        "    for idx, row in df.iterrows():\n",
        "        try:\n",
        "            chunks = load_and_chunk_pdf(row['pdf_file_name'])\n",
        "        except Exception as e:\n",
        "            print(f\"Error processing file {row['pdf_file_name']}: {e}\")\n",
        "            continue\n",
        "\n",
        "        for i, chunk in enumerate(chunks):\n",
        "            prechunk_id = i-1 if i > 0 else ''\n",
        "            postchunk_id = i+1 if i < len(chunks) - 1 else ''\n",
        "\n",
        "            expanded_rows.append({\n",
        "                'id': f\"{row['arxiv_id']}#{i}\",\n",
        "                'title': row['title'],\n",
        "                'summary': row['summary'],\n",
        "                'authors': row['authors'],\n",
        "                'arxiv_id': row['arxiv_id'],\n",
        "                'url': row['url'],\n",
        "                'chunk': chunk.page_content,\n",
        "                'prechunk_id': '' if i == 0 else f\"{row['arxiv_id']}#{prechunk_id}\",  # Previous chunk ID\n",
        "                'postchunk_id': '' if i == len(chunks) - 1 else f\"{row['arxiv_id']}#{postchunk_id}\"  # Next chunk ID\n",
        "            })\n",
        "\n",
        "    # Return a new expanded DataFrame which contents the meta data\n",
        "    return pd.DataFrame(expanded_rows)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "800cbfe3-0823-422b-8aca-3f7b453659ce",
      "metadata": {
        "id": "800cbfe3-0823-422b-8aca-3f7b453659ce"
      },
      "outputs": [],
      "source": [
        "expanded_df = expand_df(df)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "abc79733-3b22-4f9c-b211-e35123d8a850",
      "metadata": {
        "id": "abc79733-3b22-4f9c-b211-e35123d8a850"
      },
      "outputs": [],
      "source": [
        "from dotenv import load_dotenv, find_dotenv\n",
        "load_dotenv(find_dotenv(), override=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2877f6da-15cf-43d2-8cd6-7c7edb098c51",
      "metadata": {
        "id": "2877f6da-15cf-43d2-8cd6-7c7edb098c51"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "from getpass import getpass\n",
        "\n",
        "from semantic_router.encoders import OpenAIEncoder\n",
        "\n",
        "os.environ['OPENAI_API_KEY'] = os.getenv('OPENAI_API_KEY') or getpass('OpenAI API key: ')\n",
        "encoder = OpenAIEncoder(name='text-embedding-3-small')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d6036bb9-1601-47e4-b5c5-04e6b6b0a562",
      "metadata": {
        "scrolled": true,
        "id": "d6036bb9-1601-47e4-b5c5-04e6b6b0a562"
      },
      "outputs": [],
      "source": [
        "encoder('hello hallo hola salut')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a3e93d1e-7399-4e07-9a78-9a3aa440b9b7",
      "metadata": {
        "id": "a3e93d1e-7399-4e07-9a78-9a3aa440b9b7"
      },
      "outputs": [],
      "source": [
        "dims = len(encoder('hello hallo hola salut')[0])\n",
        "dims"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "050b2392-fe04-4b55-9288-b0b08c98cc29",
      "metadata": {
        "id": "050b2392-fe04-4b55-9288-b0b08c98cc29"
      },
      "outputs": [],
      "source": [
        "from pinecone import Pinecone, ServerlessSpec\n",
        "\n",
        "api_key = os.getenv('PINECONE_API_KEY') or getpass('Pinecone API key: ')\n",
        "pc = Pinecone(api_key=api_key)\n",
        "spec = ServerlessSpec(\n",
        "    cloud='aws',\n",
        "    region='us-east-1'\n",
        ")\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "269d128f-927b-43ca-b5d8-b8e17669e338",
      "metadata": {
        "id": "269d128f-927b-43ca-b5d8-b8e17669e338"
      },
      "outputs": [],
      "source": [
        "import time\n",
        "\n",
        "index_name = 'langgraph-research-agent'\n",
        "\n",
        "if index_name not in pc.list_indexes().names():\n",
        "    pc.create_index(\n",
        "        index_name,\n",
        "        dimension=dims,  # Embedding dimension (1536)\n",
        "        metric='cosine',\n",
        "        spec=spec\n",
        "    )\n",
        "\n",
        "    while not pc.describe_index(index_name).status['ready']:\n",
        "        time.sleep(1)\n",
        "\n",
        "index = pc.Index(index_name)\n",
        "time.sleep(1)\n",
        "index.describe_index_stats()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6c36f4f7-7414-479e-958a-cd75cc768dd3",
      "metadata": {
        "id": "6c36f4f7-7414-479e-958a-cd75cc768dd3"
      },
      "outputs": [],
      "source": [
        "expanded_df.iloc[:5]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7561ecf9-b142-4ca5-968f-02436403cfb0",
      "metadata": {
        "id": "7561ecf9-b142-4ca5-968f-02436403cfb0"
      },
      "outputs": [],
      "source": [
        "from tqdm.auto import tqdm\n",
        "\n",
        "data = expanded_df\n",
        "batch_size = 64\n",
        "\n",
        "for i in tqdm(range(0, len(data), batch_size)):\n",
        "    i_end = min(len(data), i + batch_size)\n",
        "    batch = data[i:i_end].to_dict(orient='records')\n",
        "\n",
        "    metadata = [{\n",
        "        'arxiv_id': r['arxiv_id'],\n",
        "        'title': r['title'],\n",
        "        'chunk': r['chunk'],\n",
        "    } for r in batch]\n",
        "\n",
        "    ids = [r['id'] for r in batch]\n",
        "    chunks = [r['chunk'] for r in batch]\n",
        "    embeds = encoder(chunks)\n",
        "    index.upsert(vectors=zip(ids, embeds, metadata))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f675265c-9e9e-4465-8c73-919c667330aa",
      "metadata": {
        "id": "f675265c-9e9e-4465-8c73-919c667330aa"
      },
      "outputs": [],
      "source": [
        "index.describe_index_stats()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1055d13d-f882-4307-aa0b-18f364c47f35",
      "metadata": {
        "scrolled": true,
        "id": "1055d13d-f882-4307-aa0b-18f364c47f35"
      },
      "outputs": [],
      "source": [
        "import requests\n",
        "arxiv_id = '1706.03762'\n",
        "res = requests.get(f'https://arxiv.org/abs/{arxiv_id}')\n",
        "res.text"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "bf3b2261-8435-4e1a-9e4d-14047b4e3323",
      "metadata": {
        "id": "bf3b2261-8435-4e1a-9e4d-14047b4e3323"
      },
      "outputs": [],
      "source": [
        "import re\n",
        "\n",
        "abstract_pattern = re.compile(\n",
        "    r'<blockquote class=\"abstract mathjax\">\\s*<span class=\"descriptor\">Abstract:</span>\\s*(.*?)\\s*</blockquote>',\n",
        "    re.DOTALL\n",
        ")\n",
        "re_match = abstract_pattern.search(res.text)\n",
        "if re_match:\n",
        "    print(re_match.group(1))\n",
        "else:\n",
        "    print('Abstract not found.')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d506422f-4a3d-47d5-81a3-5a03c7aa7ec5",
      "metadata": {
        "id": "d506422f-4a3d-47d5-81a3-5a03c7aa7ec5"
      },
      "outputs": [],
      "source": [
        "from langchain_core.tools import tool\n",
        "import requests\n",
        "import re\n",
        "\n",
        "abstract_pattern = re.compile(\n",
        "    r'<blockquote class=\"abstract mathjax\">\\s*<span class=\"descriptor\">Abstract:</span>\\s*(.*?)\\s*</blockquote>',\n",
        "    re.DOTALL\n",
        ")\n",
        "\n",
        "@tool('fetch_arxiv')\n",
        "def fetch_arxiv(arxiv_id: str) -> str:\n",
        "    '''Fetches the abstract from an ArXiv paper given its ArXiv ID.\n",
        "\n",
        "    Args:\n",
        "        arxiv_id (str): The ArXiv paper ID.\n",
        "\n",
        "    Returns:\n",
        "        str: The extracted abstract text from the ArXiv paper.\n",
        "    '''\n",
        "\n",
        "    res = requests.get(f'https://arxiv.org/abs/{arxiv_id}')\n",
        "\n",
        "    re_match = abstract_pattern.search(res.text)\n",
        "\n",
        "    return re_match.group(1) if re_match else 'Abstract not found.'\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e7939006-a53e-41a8-88d4-9a036cb5bb66",
      "metadata": {
        "id": "e7939006-a53e-41a8-88d4-9a036cb5bb66"
      },
      "outputs": [],
      "source": [
        "arxiv_id = '1706.03762'\n",
        "output = fetch_arxiv.invoke(input={'arxiv_id': arxiv_id})\n",
        "print(output)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "519ab293-c41f-427c-ac9d-265307b18db7",
      "metadata": {
        "id": "519ab293-c41f-427c-ac9d-265307b18db7"
      },
      "outputs": [],
      "source": [
        "from dotenv import load_dotenv, find_dotenv\n",
        "load_dotenv(find_dotenv(), override=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7968a061-30f4-495a-839b-d56f22770672",
      "metadata": {
        "id": "7968a061-30f4-495a-839b-d56f22770672"
      },
      "outputs": [],
      "source": [
        "from serpapi import GoogleSearch\n",
        "import os\n",
        "from getpass import getpass\n",
        "\n",
        "serpapi_params = {\n",
        "    'engine': 'google',\n",
        "    'api_key': os.getenv('SERPAPI_KEY') or getpass('SerpAPI key: ')\n",
        "}\n",
        "search = GoogleSearch({\n",
        "    **serpapi_params,\n",
        "    'q': 'water',\n",
        "    'num': 5\n",
        "})\n",
        "\n",
        "results = search.get_dict().get('organic_results', [])\n",
        "formatted_results = '\\n---\\n'.join(\n",
        "    ['\\n'.join([x['title'], x['snippet'], x['link']]) for x in results]\n",
        ")\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7303a50c-68f6-4293-8ea4-4b0a60782339",
      "metadata": {
        "id": "7303a50c-68f6-4293-8ea4-4b0a60782339"
      },
      "outputs": [],
      "source": [
        "print(formatted_results)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "247da198-6afd-4115-b34b-4936e8c69373",
      "metadata": {
        "id": "247da198-6afd-4115-b34b-4936e8c69373"
      },
      "outputs": [],
      "source": [
        "from serpapi import GoogleSearch\n",
        "\n",
        "@tool('web_search')\n",
        "def web_search(query: str) -> str:\n",
        "    '''Finds general knowledge information using a Google search.\n",
        "\n",
        "    Args:\n",
        "        query (str): The search query string.\n",
        "\n",
        "    Returns:\n",
        "        str: A formatted string of the top search results, including title, snippet, and link.\n",
        "    '''\n",
        "\n",
        "    search = GoogleSearch({\n",
        "        **serpapi_params,\n",
        "        'q': query,\n",
        "        'num': 5\n",
        "    })\n",
        "\n",
        "    results = search.get_dict().get('organic_results', [])\n",
        "    formatted_results = '\\n---\\n'.join(\n",
        "        ['\\n'.join([x['title'], x['snippet'], x['link']]) for x in results]\n",
        "    )\n",
        "    return formatted_results if results else 'No results found.'\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "70901700-0e16-4958-9e99-c8f64dcfcc6e",
      "metadata": {
        "id": "70901700-0e16-4958-9e99-c8f64dcfcc6e"
      },
      "outputs": [],
      "source": [
        "output = web_search.invoke(input={'query': 'water on mars'})\n",
        "print(output)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "83193680-a36a-4aa7-9a64-f649cffc665e",
      "metadata": {
        "id": "83193680-a36a-4aa7-9a64-f649cffc665e"
      },
      "outputs": [],
      "source": [
        "def format_rag_contexts(matches: list) -> str:\n",
        "    '''Formats the retrieved context matches into a readable string format.\n",
        "\n",
        "    Args:\n",
        "        matches (list): A list of matched documents with metadata.\n",
        "\n",
        "    Returns:\n",
        "        str: A formatted string of document titles, chunks, and ArXiv IDs.\n",
        "    '''\n",
        "    formatted_results = []\n",
        "    for x in matches:\n",
        "        text = (\n",
        "            f\"Title: {x['metadata']['title']}\\n\"\n",
        "            f\"Chunk: {x['metadata']['chunk']}\\n\"\n",
        "            f\"ArXiv ID: {x['metadata']['arxiv_id']}\\n\"\n",
        "        )\n",
        "        formatted_results.append(text)\n",
        "    return '\\n---\\n'.join(formatted_results)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a5938e85-3697-457b-a408-fac019ef8070",
      "metadata": {
        "id": "a5938e85-3697-457b-a408-fac019ef8070"
      },
      "outputs": [],
      "source": [
        "from langchain_core.tools import tool\n",
        "\n",
        "@tool\n",
        "def rag_search_filter(query: str, arxiv_id: str) -> str:\n",
        "    '''Finds information from the ArXiv database using a natural language query and a specific ArXiv ID.\n",
        "\n",
        "    Args:\n",
        "        query (str): The search query in natural language.\n",
        "        arxiv_id (str): The ArXiv ID of the specific paper to filter by.\n",
        "\n",
        "    Returns:\n",
        "        str: A formatted string of relevant document contexts.\n",
        "    '''\n",
        "\n",
        "    xq = encoder([query])\n",
        "    xc = index.query(vector=xq, top_k=6, include_metadata=True, filter={'arxiv_id': arxiv_id})\n",
        "    return format_rag_contexts(xc['matches'])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "57e476c9-f570-44d8-98da-110439fbe79b",
      "metadata": {
        "id": "57e476c9-f570-44d8-98da-110439fbe79b"
      },
      "outputs": [],
      "source": [
        "@tool('rag_search')\n",
        "def rag_search(query: str) -> str:\n",
        "    '''Finds specialist information on AI using a natural language query.\n",
        "\n",
        "    Args:\n",
        "        query (str): The search query in natural language.\n",
        "\n",
        "    Returns:\n",
        "        str: A formatted string of relevant document contexts.\n",
        "    '''\n",
        "\n",
        "    xq = encoder([query])\n",
        "    xc = index.query(vector=xq, top_k=5, include_metadata=True)\n",
        "    return format_rag_contexts(xc['matches'])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "fefece23-e266-4ca1-9ceb-90c6aa20f361",
      "metadata": {
        "id": "fefece23-e266-4ca1-9ceb-90c6aa20f361"
      },
      "outputs": [],
      "source": [
        "from langchain_core.tools import tool\n",
        "\n",
        "@tool\n",
        "def final_answer(\n",
        "    introduction: str,\n",
        "    research_steps: str or list,\n",
        "    main_body: str,\n",
        "    conclusion: str,\n",
        "    sources: str or list\n",
        ") -> str:\n",
        "    '''Returns a natural language response in the form of a research report.\n",
        "\n",
        "    Args:\n",
        "        introduction (str): A short paragraph introducing the user's question and the topic.\n",
        "        research_steps (str or list): Bullet points or text explaining the steps taken for research.\n",
        "        main_body (str): The bulk of the answer, 3-4 paragraphs long, providing high-quality information.\n",
        "        conclusion (str): A short paragraph summarizing the findings.\n",
        "        sources (str or list): A list or text providing the sources referenced during the research.\n",
        "\n",
        "    Returns:\n",
        "        str: A formatted research report string.\n",
        "    '''\n",
        "\n",
        "    if isinstance(research_steps, list):\n",
        "        research_steps = '\\n'.join([f'- {r}' for r in research_steps])\n",
        "\n",
        "    if isinstance(sources, list):\n",
        "        sources = '\\n'.join([f'- {s}' for s in sources])\n",
        "\n",
        "    return f'{introduction}\\n\\nResearch Steps:\\n{research_steps}\\n\\nMain Body:\\n{main_body}\\n\\n \\\n",
        "    Conclusion:\\n{conclusion}\\n\\nSources:\\n{sources}'\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "36ced764-167d-4b5f-bdde-96e90c33a5f4",
      "metadata": {
        "id": "36ced764-167d-4b5f-bdde-96e90c33a5f4"
      },
      "source": [
        "## 11 - Initializing the \"Oracle\" LLM"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "eb1941ac-aaf6-4a01-af18-6bcf604c93b0",
      "metadata": {
        "id": "eb1941ac-aaf6-4a01-af18-6bcf604c93b0"
      },
      "outputs": [],
      "source": [
        "from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder\n",
        "\n",
        "system_prompt = (\n",
        "    '''You are the oracle, the great AI decision-maker.\n",
        "    Given the user's query, you must decide what to do with it based on the\n",
        "    list of tools provided to you.\n",
        "\n",
        "    If you see that a tool has been used (in the scratchpad) with a particular\n",
        "    query, do NOT use that same tool with the same query again. Also, do NOT use\n",
        "    any tool more than twice (i.e., if the tool appears in the scratchpad twice, do\n",
        "    not use it again).\n",
        "\n",
        "    You should aim to collect information from a diverse range of sources before\n",
        "    providing the answer to the user. Once you have collected plenty of information\n",
        "    to answer the user's question (stored in the scratchpad), use the final_answer tool.'''\n",
        ")\n",
        "\n",
        "\n",
        "prompt = ChatPromptTemplate.from_messages([\n",
        "    ('system', system_prompt),\n",
        "    MessagesPlaceholder(variable_name='chat_history'),\n",
        "    ('user', '{input}'),\n",
        "    ('assistant', 'scratchpad: {scratchpad}'),\n",
        "])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8cf002d5-c1b1-4aed-965c-90160f265144",
      "metadata": {
        "id": "8cf002d5-c1b1-4aed-965c-90160f265144"
      },
      "outputs": [],
      "source": [
        "from langchain_core.messages import ToolCall, ToolMessage\n",
        "from langchain_openai import ChatOpenAI\n",
        "import os\n",
        "\n",
        "llm = ChatOpenAI(\n",
        "    model='gpt-4o',\n",
        "    openai_api_key=os.environ['OPENAI_API_KEY'],\n",
        "    temperature=0\n",
        ")\n",
        "tools = [\n",
        "    rag_search_filter,\n",
        "    rag_search,\n",
        "    fetch_arxiv,\n",
        "    web_search,\n",
        "    final_answer\n",
        "]\n",
        "\n",
        "def create_scratchpad(intermediate_steps: list[ToolCall]) -> str:\n",
        "    research_steps = []\n",
        "\n",
        "    for i, action in enumerate(intermediate_steps):\n",
        "        if action.log != 'TBD':\n",
        "            research_steps.append(\n",
        "                f'Tool: {action.tool}, input: {action.tool_input}\\n'\n",
        "                f'Output: {action.log}'\n",
        "            )\n",
        "    return '\\n---\\n'.join(research_steps)\n",
        "\n",
        "oracle = (\n",
        "    {\n",
        "        'input': lambda x: x['input'],\n",
        "        'chat_history': lambda x: x['chat_history'],\n",
        "        'scratchpad': lambda x: create_scratchpad(intermediate_steps=x['intermediate_steps']),\n",
        "    }\n",
        "    | prompt\n",
        "    | llm.bind_tools(tools, tool_choice='any')\n",
        ")\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f9687cca-2406-47bb-b69c-d8dcadb4a242",
      "metadata": {
        "id": "f9687cca-2406-47bb-b69c-d8dcadb4a242"
      },
      "source": [
        "## 12 -  Testing the Oracle and the Tools"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1f9b6e43-c767-40c1-a5c8-f9915eab5a0e",
      "metadata": {
        "id": "1f9b6e43-c767-40c1-a5c8-f9915eab5a0e"
      },
      "outputs": [],
      "source": [
        "input = 'What is the ArXiv paper with the ID 2407.21783 all about?'\n",
        "inputs = {\n",
        "    'input': input,\n",
        "    'chat_history': [],\n",
        "    'intermediate_steps': [],\n",
        "}\n",
        "out = oracle.invoke(inputs)\n",
        "print(out)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "48c048e5-d647-417c-b433-2b6682265aed",
      "metadata": {
        "id": "48c048e5-d647-417c-b433-2b6682265aed"
      },
      "outputs": [],
      "source": [
        "out.tool_calls[0]['name']\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8e54264a-4621-44bc-a8d3-097d39160a7a",
      "metadata": {
        "id": "8e54264a-4621-44bc-a8d3-097d39160a7a"
      },
      "outputs": [],
      "source": [
        "out.tool_calls[0]['args']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b4aec02d-2559-461a-aa3f-c3e05cb4f8b2",
      "metadata": {
        "id": "b4aec02d-2559-461a-aa3f-c3e05cb4f8b2"
      },
      "outputs": [],
      "source": [
        "def run_oracle(state: dict) -> dict:\n",
        "    '''Runs the oracle and processes the output to extract tool information.\n",
        "\n",
        "    Args:\n",
        "        state (dict): The current state containing the 'intermediate_steps'.\n",
        "\n",
        "    Returns:\n",
        "        dict: A new state with updated 'intermediate_steps' including the tool action.\n",
        "    '''\n",
        "\n",
        "    print('run_oracle')\n",
        "    print(f'intermediate_steps: {state[\"intermediate_steps\"]}')\n",
        "\n",
        "    out = oracle.invoke(state)\n",
        "    tool_name = out.tool_calls[0]['name']\n",
        "    tool_args = out.tool_calls[0]['args']\n",
        "    action_out = AgentAction(\n",
        "        tool=tool_name,\n",
        "        tool_input=tool_args,\n",
        "        log='TBD'\n",
        "    )\n",
        "    return {\n",
        "        'intermediate_steps': [action_out]\n",
        "    }\n",
        "\n",
        "\n",
        "def router(state: dict) -> str:\n",
        "    '''Determines the next tool to use based on the current state.\n",
        "\n",
        "    Args:\n",
        "        state (dict): The current state containing 'intermediate_steps'.\n",
        "\n",
        "    Returns:\n",
        "        str: The name of the tool to use next.\n",
        "    '''\n",
        "\n",
        "    if isinstance(state['intermediate_steps'], list):\n",
        "        return state['intermediate_steps'][-1].tool\n",
        "    else:\n",
        "        print('Router invalid format')\n",
        "        return 'final_answer'\n",
        "\n",
        "\n",
        "tool_str_to_func = {\n",
        "    'rag_search_filter': rag_search_filter,\n",
        "    'rag_search': rag_search,\n",
        "    'fetch_arxiv': fetch_arxiv,\n",
        "    'web_search': web_search,\n",
        "    'final_answer': final_answer\n",
        "}\n",
        "\n",
        "def run_tool(state: dict) -> dict:\n",
        "    '''Executes the appropriate tool based on the current state.\n",
        "\n",
        "    Args:\n",
        "        state (dict): The current state containing the 'intermediate_steps'.\n",
        "\n",
        "    Returns:\n",
        "        dict: A new state with updated 'intermediate_steps' including the tool's result.\n",
        "    '''\n",
        "\n",
        "    tool_name = state['intermediate_steps'][-1].tool\n",
        "    tool_args = state['intermediate_steps'][-1].tool_input\n",
        "\n",
        "    print(f'{tool_name}.invoke(input={tool_args})')\n",
        "\n",
        "    out = tool_str_to_func[tool_name].invoke(input=tool_args)\n",
        "\n",
        "    action_out = AgentAction(\n",
        "        tool=tool_name,\n",
        "        tool_input=tool_args,\n",
        "        log=str(out)\n",
        "    )\n",
        "\n",
        "    return {'intermediate_steps': [action_out]}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4c74e9b7-de23-4ca9-91d8-44fc3e802ce8",
      "metadata": {
        "id": "4c74e9b7-de23-4ca9-91d8-44fc3e802ce8"
      },
      "outputs": [],
      "source": [
        "from typing import TypedDict, Annotated, List\n",
        "from langchain_core.agents import AgentAction\n",
        "from langchain_core.messages import BaseMessage\n",
        "import operator\n",
        "\n",
        "class AgentState(TypedDict):\n",
        "    '''Represents the state of an agent.'''\n",
        "\n",
        "    input: str\n",
        "    chat_history: List[BaseMessage]\n",
        "    intermediate_steps: Annotated[List[tuple[AgentAction, str]], operator.add]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "082644ad-8f9d-45f6-ad6b-d7c16d913bdd",
      "metadata": {
        "id": "082644ad-8f9d-45f6-ad6b-d7c16d913bdd"
      },
      "outputs": [],
      "source": [
        "from langgraph.graph import StateGraph, END\n",
        "\n",
        "graph = StateGraph(AgentState)\n",
        "graph.add_node('oracle', run_oracle)\n",
        "graph.add_node('rag_search_filter', run_tool)\n",
        "graph.add_node('rag_search', run_tool)\n",
        "graph.add_node('fetch_arxiv', run_tool)\n",
        "graph.add_node('web_search', run_tool)\n",
        "graph.add_node('final_answer', run_tool)\n",
        "\n",
        "graph.set_entry_point('oracle')\n",
        "graph.add_conditional_edges(source='oracle', path=router)\n",
        "for tool_obj in tools:\n",
        "    if tool_obj.name != 'final_answer':\n",
        "        graph.add_edge(tool_obj.name, 'oracle')\n",
        "\n",
        "graph.add_edge('final_answer', END)\n",
        "runnable = graph.compile()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9425ac03-c31b-4b8f-94bc-7242f296b1f6",
      "metadata": {
        "id": "9425ac03-c31b-4b8f-94bc-7242f296b1f6"
      },
      "outputs": [],
      "source": [
        "from IPython.display import Image, display\n",
        "display(Image(runnable.get_graph().draw_mermaid_png()))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a900e779-d3f6-4176-92e1-a744b090ee67",
      "metadata": {
        "id": "a900e779-d3f6-4176-92e1-a744b090ee67"
      },
      "outputs": [],
      "source": [
        "output = runnable.invoke({\n",
        "    'input': 'Tell me something interesting about Dynamic Backtracking AI and LLMs',\n",
        "    'chat_history': [],\n",
        "})\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "14fa5027-2b1b-4dc3-a98e-2650778bf127",
      "metadata": {
        "id": "14fa5027-2b1b-4dc3-a98e-2650778bf127"
      },
      "outputs": [],
      "source": [
        "def build_report(output: dict) -> str:\n",
        "    '''Builds a formatted report based on the oracle's output.\n",
        "\n",
        "    Args:\n",
        "        output (dict): A dictionary containing the various sections of the report (graph's output).\n",
        "\n",
        "    Returns:\n",
        "        str: A formatted string containing the full research report.\n",
        "    '''\n",
        "    research_steps = output['research_steps']\n",
        "    if isinstance(research_steps, list):\n",
        "        research_steps = '\\n'.join([f'- {r}' for r in research_steps])\n",
        "\n",
        "    sources = output['sources']\n",
        "    if isinstance(sources, list):\n",
        "        sources = '\\n'.join([f'- {s}' for s in sources])\n",
        "\n",
        "    return f\"\"\"\n",
        "        INTRODUCTION\n",
        "        ------------\n",
        "        {output['introduction']}\n",
        "\n",
        "        RESEARCH STEPS\n",
        "        --------------\n",
        "        {research_steps}\n",
        "\n",
        "        REPORT\n",
        "        ------\n",
        "        {output['main_body']}\n",
        "\n",
        "        CONCLUSION\n",
        "        ----------\n",
        "        {output['conclusion']}\n",
        "\n",
        "        SOURCES\n",
        "        -------\n",
        "        {sources}\n",
        "    \"\"\"\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "aa0a7543-01ba-4511-bcc0-e6d30df52e51",
      "metadata": {
        "id": "aa0a7543-01ba-4511-bcc0-e6d30df52e51"
      },
      "outputs": [],
      "source": [
        "# Run the graph with input.\n",
        "output = runnable.invoke({\n",
        "    'input': 'Tell me something interesting about Dynamic Backtracking AI and LLMs',\n",
        "    'chat_history': [],\n",
        "})"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "665e08cc-61ec-486d-8ae7-c98decdfafe0",
      "metadata": {
        "id": "665e08cc-61ec-486d-8ae7-c98decdfafe0"
      },
      "outputs": [],
      "source": [
        "output['intermediate_steps'][-1].tool_input"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "129bb334-b71a-4aea-802d-e29630854152",
      "metadata": {
        "id": "129bb334-b71a-4aea-802d-e29630854152"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f6bad122-b4dc-44ec-be8b-9db42ffdc666",
      "metadata": {
        "id": "f6bad122-b4dc-44ec-be8b-9db42ffdc666"
      },
      "outputs": [],
      "source": [
        "output = runnable.invoke({\n",
        "    'input': 'tell me about FIFA World Cup 26',\n",
        "    'chat_history': []\n",
        "})\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "047ea374-c4a4-40c5-9feb-3221912906b9",
      "metadata": {
        "id": "047ea374-c4a4-40c5-9feb-3221912906b9"
      },
      "outputs": [],
      "source": [
        "report = build_report(\n",
        "    output=output['intermediate_steps'][-1].tool_input\n",
        ")\n",
        "\n",
        "print(report)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "130b6273-b4b6-4592-8d19-42134935f443",
      "metadata": {
        "id": "130b6273-b4b6-4592-8d19-42134935f443"
      },
      "outputs": [],
      "source": [
        "output = runnable.invoke({\n",
        "    'input': 'Create a summary about this AxXiv paper with the ID 2409.17990',\n",
        "    'chat_history': []\n",
        "})\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "79e3c7a7-82c8-415b-9216-e15ac5544f56",
      "metadata": {
        "id": "79e3c7a7-82c8-415b-9216-e15ac5544f56"
      },
      "outputs": [],
      "source": [
        "report = build_report(\n",
        "    output=output['intermediate_steps'][-1].tool_input\n",
        ")\n",
        "\n",
        "print(report)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c7c6e89f-38f9-4994-821f-3588ed683c0a",
      "metadata": {
        "id": "c7c6e89f-38f9-4994-821f-3588ed683c0a",
        "outputId": "cc768684-5a24-4186-a59d-cd9998e97b71"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "run_oracle\n",
            "intermediate_steps: []\n",
            "rag_search.invoke(input={'query': 'future of LLM Agents'})\n",
            "run_oracle\n",
            "intermediate_steps: [AgentAction(tool='rag_search', tool_input={'query': 'future of LLM Agents'}, log='TBD'), AgentAction(tool='rag_search', tool_input={'query': 'future of LLM Agents'}, log='Title: On Planning while Learning\\nChunk: one go al/, if an e/\\x0ecient satisfactory multi/-agent plan for achievingthese go als exists/, then ther e exists such an e/\\x0ecient satisfactory multi/-agent plan that c anb e enc o de d in p olynomial sp ac e/, and b e veri/\\x0ce d in p olynomial time/.Pro of/: In this case eac h agen t kno ws the goal of the other agen t/, and hence it is clear thatit migh t learn only facts ab out the p ossible initial states and b eha viors/.Giv en that there is only a p olynomial n um b er of p ossible initial states and en\\nArXiv ID: 9409101v1\\n\\n---\\nTitle: A Market-Oriented Programming Environment and its Application to\\n  Distributed Multicommodity Flow Problems\\nChunk: can also b e addressed within w alras /. T o do so/, w e in tro duce y etanother sort of pro ducer agen t/. These new agen ts/, called arbitr ageurs /, act as sp ecializedmiddlemen/, monitoring isolated pieces of the net w ork for ine/\\x0eciencies/. An arbitrageurAi/;j/;k\\nArXiv ID: 9308102v1\\n\\n---\\nTitle: On Planning while Learning\\nChunk: k/, in p olynomialtime/, whether it determines a satisfactory m ulti/-agen t plan/.Lemma /6/./3 /: Given a quasi/-mo der ate multi/-agent Planning while L e arning system S /, wher ee ach agent has n p ossible go als /(wher e n is p olynomial ly b ounde d in the actual r epr esentationsize/)/, ther e exists a quasi/-mo der ate multi/-agent Planning while L e arning system S\\nArXiv ID: 9409101v1\\n\\n---\\nTitle: Software Agents: Completing Patterns and Constructing User Interfaces\\nChunk: S \\nCHLIMMER  \\n& H \\nERMENS \\n84 \\n• \\nUser adjustable \\n—Can the user tune the system parameters manually?\\nHere we describe related system s that exhibit propertie s in each of t hese agent dimensions .\\nOur note taking softwar e utilizes the  \\nanticipation \\n user interface technique pioneered by\\nEager (Cypher , 1991). Eager is a non-intrusive system that learns to perform iterative proce-\\ndures by watching the user . As such, it is a learning apprentice, a software agent , and an\\nArXiv ID: 9311102v1\\n\\n---\\nTitle: On Planning while Learning\\nChunk: /0/(wher equasi/-mo der ate r efers to the actual r epr esentation size of the original system S /)/, with aunique go al for e ach agent/, such that ther e exists an /(e/\\x0ecient/) satisfactory multi/-agent planin S\\n/0if and only if ther e exists an /(e/\\x0ecient/) satisfactory multi/-agent plan in S /.Pro of/: S\\n/0will b e built as follo ws/. The observ able states of agen t i in S\\n/0will b e the cartesianpro duct of the observ able states of agen t i in S with the set of states/:f star ti\\n/; obser v ei/1\\nArXiv ID: 9409101v1\\n')]\n",
            "web_search.invoke(input={'query': 'future of LLM Agents'})\n",
            "run_oracle\n",
            "intermediate_steps: [AgentAction(tool='rag_search', tool_input={'query': 'future of LLM Agents'}, log='TBD'), AgentAction(tool='rag_search', tool_input={'query': 'future of LLM Agents'}, log='Title: On Planning while Learning\\nChunk: one go al/, if an e/\\x0ecient satisfactory multi/-agent plan for achievingthese go als exists/, then ther e exists such an e/\\x0ecient satisfactory multi/-agent plan that c anb e enc o de d in p olynomial sp ac e/, and b e veri/\\x0ce d in p olynomial time/.Pro of/: In this case eac h agen t kno ws the goal of the other agen t/, and hence it is clear thatit migh t learn only facts ab out the p ossible initial states and b eha viors/.Giv en that there is only a p olynomial n um b er of p ossible initial states and en\\nArXiv ID: 9409101v1\\n\\n---\\nTitle: A Market-Oriented Programming Environment and its Application to\\n  Distributed Multicommodity Flow Problems\\nChunk: can also b e addressed within w alras /. T o do so/, w e in tro duce y etanother sort of pro ducer agen t/. These new agen ts/, called arbitr ageurs /, act as sp ecializedmiddlemen/, monitoring isolated pieces of the net w ork for ine/\\x0eciencies/. An arbitrageurAi/;j/;k\\nArXiv ID: 9308102v1\\n\\n---\\nTitle: On Planning while Learning\\nChunk: k/, in p olynomialtime/, whether it determines a satisfactory m ulti/-agen t plan/.Lemma /6/./3 /: Given a quasi/-mo der ate multi/-agent Planning while L e arning system S /, wher ee ach agent has n p ossible go als /(wher e n is p olynomial ly b ounde d in the actual r epr esentationsize/)/, ther e exists a quasi/-mo der ate multi/-agent Planning while L e arning system S\\nArXiv ID: 9409101v1\\n\\n---\\nTitle: Software Agents: Completing Patterns and Constructing User Interfaces\\nChunk: S \\nCHLIMMER  \\n& H \\nERMENS \\n84 \\n• \\nUser adjustable \\n—Can the user tune the system parameters manually?\\nHere we describe related system s that exhibit propertie s in each of t hese agent dimensions .\\nOur note taking softwar e utilizes the  \\nanticipation \\n user interface technique pioneered by\\nEager (Cypher , 1991). Eager is a non-intrusive system that learns to perform iterative proce-\\ndures by watching the user . As such, it is a learning apprentice, a software agent , and an\\nArXiv ID: 9311102v1\\n\\n---\\nTitle: On Planning while Learning\\nChunk: /0/(wher equasi/-mo der ate r efers to the actual r epr esentation size of the original system S /)/, with aunique go al for e ach agent/, such that ther e exists an /(e/\\x0ecient/) satisfactory multi/-agent planin S\\n/0if and only if ther e exists an /(e/\\x0ecient/) satisfactory multi/-agent plan in S /.Pro of/: S\\n/0will b e built as follo ws/. The observ able states of agen t i in S\\n/0will b e the cartesianpro duct of the observ able states of agen t i in S with the set of states/:f star ti\\n/; obser v ei/1\\nArXiv ID: 9409101v1\\n'), AgentAction(tool='web_search', tool_input={'query': 'future of LLM Agents'}, log='TBD'), AgentAction(tool='web_search', tool_input={'query': 'future of LLM Agents'}, log=\"The future of AI agents with Yohei Nakajima\\nThe future is going to be full of AI agents, but there are still a lot of open questions on how to get there & what that world will look like.\\nhttps://medium.com/around-the-prompt/the-future-of-ai-agents-with-yohei-nakajima-2602e32a4765\\n---\\nThe Future of LLM-Based Agents: Making the Boxes Bigger\\nThe Future of LLM-Based Agents: Making the Boxes Bigger | AI Agents are a promising approach for using Large Language Models (LLMs) to do real work.\\nhttps://www.arcus.co/blog/ai-agents-pt-2\\n---\\nLLM Agents: Their Past, Present, and Future\\nThe future of LLM agents is not just about creating smarter machines but about enhancing human capabilities and solving real-world problems ...\\nhttps://medium.com/@saurabhharak/llm-agents-their-past-present-and-future-22988c29a5f8\\n---\\nThe Future of Generative AI Agents\\nA series of in-depth conversations with leading AI researchers where we'll explore how state-of-the-art models are being applied in the real world.\\nhttps://foundationcapital.com/the-future-of-generative-agents/\")]\n",
            "rag_search_filter.invoke(input={'query': 'future of LLM Agents', 'arxiv_id': '9409101v1'})\n",
            "run_oracle\n",
            "intermediate_steps: [AgentAction(tool='rag_search', tool_input={'query': 'future of LLM Agents'}, log='TBD'), AgentAction(tool='rag_search', tool_input={'query': 'future of LLM Agents'}, log='Title: On Planning while Learning\\nChunk: one go al/, if an e/\\x0ecient satisfactory multi/-agent plan for achievingthese go als exists/, then ther e exists such an e/\\x0ecient satisfactory multi/-agent plan that c anb e enc o de d in p olynomial sp ac e/, and b e veri/\\x0ce d in p olynomial time/.Pro of/: In this case eac h agen t kno ws the goal of the other agen t/, and hence it is clear thatit migh t learn only facts ab out the p ossible initial states and b eha viors/.Giv en that there is only a p olynomial n um b er of p ossible initial states and en\\nArXiv ID: 9409101v1\\n\\n---\\nTitle: A Market-Oriented Programming Environment and its Application to\\n  Distributed Multicommodity Flow Problems\\nChunk: can also b e addressed within w alras /. T o do so/, w e in tro duce y etanother sort of pro ducer agen t/. These new agen ts/, called arbitr ageurs /, act as sp ecializedmiddlemen/, monitoring isolated pieces of the net w ork for ine/\\x0eciencies/. An arbitrageurAi/;j/;k\\nArXiv ID: 9308102v1\\n\\n---\\nTitle: On Planning while Learning\\nChunk: k/, in p olynomialtime/, whether it determines a satisfactory m ulti/-agen t plan/.Lemma /6/./3 /: Given a quasi/-mo der ate multi/-agent Planning while L e arning system S /, wher ee ach agent has n p ossible go als /(wher e n is p olynomial ly b ounde d in the actual r epr esentationsize/)/, ther e exists a quasi/-mo der ate multi/-agent Planning while L e arning system S\\nArXiv ID: 9409101v1\\n\\n---\\nTitle: Software Agents: Completing Patterns and Constructing User Interfaces\\nChunk: S \\nCHLIMMER  \\n& H \\nERMENS \\n84 \\n• \\nUser adjustable \\n—Can the user tune the system parameters manually?\\nHere we describe related system s that exhibit propertie s in each of t hese agent dimensions .\\nOur note taking softwar e utilizes the  \\nanticipation \\n user interface technique pioneered by\\nEager (Cypher , 1991). Eager is a non-intrusive system that learns to perform iterative proce-\\ndures by watching the user . As such, it is a learning apprentice, a software agent , and an\\nArXiv ID: 9311102v1\\n\\n---\\nTitle: On Planning while Learning\\nChunk: /0/(wher equasi/-mo der ate r efers to the actual r epr esentation size of the original system S /)/, with aunique go al for e ach agent/, such that ther e exists an /(e/\\x0ecient/) satisfactory multi/-agent planin S\\n/0if and only if ther e exists an /(e/\\x0ecient/) satisfactory multi/-agent plan in S /.Pro of/: S\\n/0will b e built as follo ws/. The observ able states of agen t i in S\\n/0will b e the cartesianpro duct of the observ able states of agen t i in S with the set of states/:f star ti\\n/; obser v ei/1\\nArXiv ID: 9409101v1\\n'), AgentAction(tool='web_search', tool_input={'query': 'future of LLM Agents'}, log='TBD'), AgentAction(tool='web_search', tool_input={'query': 'future of LLM Agents'}, log=\"The future of AI agents with Yohei Nakajima\\nThe future is going to be full of AI agents, but there are still a lot of open questions on how to get there & what that world will look like.\\nhttps://medium.com/around-the-prompt/the-future-of-ai-agents-with-yohei-nakajima-2602e32a4765\\n---\\nThe Future of LLM-Based Agents: Making the Boxes Bigger\\nThe Future of LLM-Based Agents: Making the Boxes Bigger | AI Agents are a promising approach for using Large Language Models (LLMs) to do real work.\\nhttps://www.arcus.co/blog/ai-agents-pt-2\\n---\\nLLM Agents: Their Past, Present, and Future\\nThe future of LLM agents is not just about creating smarter machines but about enhancing human capabilities and solving real-world problems ...\\nhttps://medium.com/@saurabhharak/llm-agents-their-past-present-and-future-22988c29a5f8\\n---\\nThe Future of Generative AI Agents\\nA series of in-depth conversations with leading AI researchers where we'll explore how state-of-the-art models are being applied in the real world.\\nhttps://foundationcapital.com/the-future-of-generative-agents/\"), AgentAction(tool='rag_search_filter', tool_input={'query': 'future of LLM Agents', 'arxiv_id': '9409101v1'}, log='TBD'), AgentAction(tool='rag_search_filter', tool_input={'query': 'future of LLM Agents', 'arxiv_id': '9409101v1'}, log=\"Title: On Planning while Learning\\nChunk: one go al/, if an e/\\x0ecient satisfactory multi/-agent plan for achievingthese go als exists/, then ther e exists such an e/\\x0ecient satisfactory multi/-agent plan that c anb e enc o de d in p olynomial sp ac e/, and b e veri/\\x0ce d in p olynomial time/.Pro of/: In this case eac h agen t kno ws the goal of the other agen t/, and hence it is clear thatit migh t learn only facts ab out the p ossible initial states and b eha viors/.Giv en that there is only a p olynomial n um b er of p ossible initial states and en\\nArXiv ID: 9409101v1\\n\\n---\\nTitle: On Planning while Learning\\nChunk: k/, in p olynomialtime/, whether it determines a satisfactory m ulti/-agen t plan/.Lemma /6/./3 /: Given a quasi/-mo der ate multi/-agent Planning while L e arning system S /, wher ee ach agent has n p ossible go als /(wher e n is p olynomial ly b ounde d in the actual r epr esentationsize/)/, ther e exists a quasi/-mo der ate multi/-agent Planning while L e arning system S\\nArXiv ID: 9409101v1\\n\\n---\\nTitle: On Planning while Learning\\nChunk: /0/(wher equasi/-mo der ate r efers to the actual r epr esentation size of the original system S /)/, with aunique go al for e ach agent/, such that ther e exists an /(e/\\x0ecient/) satisfactory multi/-agent planin S\\n/0if and only if ther e exists an /(e/\\x0ecient/) satisfactory multi/-agent plan in S /.Pro of/: S\\n/0will b e built as follo ws/. The observ able states of agen t i in S\\n/0will b e the cartesianpro duct of the observ able states of agen t i in S with the set of states/:f star ti\\n/; obser v ei/1\\nArXiv ID: 9409101v1\\n\\n---\\nTitle: On Planning while Learning\\nChunk: /4An in teresting feature of the m ulti/-agen t case is that an agen t migh t not b e familiarwith the goal and the initial state of the other agen t/. Hence/, Planning while Learning refersno w to the case in whic h an agen t tries to ac hiev e its goal while learning ab out the b eha viorof the en vironmen t/, and ab out the goals and initial states of other agen ts/.De/\\x0cnition /6/./2 /: A multi/-agent Planning while L e arning system is a tupleSm\\n/= /( Q/1\\n/; Q/2\\n/; A /; q\\n/1/0\\n/; q\\n/2/0\\n/; B /; b/0\\nArXiv ID: 9409101v1\\n\\n---\\nTitle: On Planning while Learning\\nChunk: On Planning while Learningof other agen ts/' mo v emen ts/. It is easy to see that similar scenarios o ccur in the trauma/-careexample and in man y other natural systems/.W e no w sho w that our o/\\x0b/-line tractabilit y result can b e extended to the m ulti/-agen tcase as w ell/. W e will use the follo wing t w o lemmas/.Lemma /6/./2 /: Given a quasi/-mo der ate multi/-agent Planning while L e arning system/, wher ee ach agent has only one go al/, if an e/\\x0ecient satisfactory multi/-agent plan for\\nArXiv ID: 9409101v1\\n\\n---\\nTitle: On Planning while Learning\\nChunk: /) and initial state of the other agen t/, and regardlessof the initial b eha vior of the en vironmen t/. An e/\\x0ecient satisfactory multi/-agent plan is asatisfactory m ulti/-agen t plan that consists of plans whic h are decision trees of p olynomialdepth/.The ab o v e de/\\x0cnition captures in tuitiv e situations of Planning while Learning in m ulti/-agen t domains/. Assume for example that there are t w o forces that ha v e to mo v e in thehostile en vironmen t of Section /2/. They start mo ving on /5AM/,\\nArXiv ID: 9409101v1\\n\")]\n",
            "final_answer.invoke(input={'introduction': 'The future of Large Language Model (LLM) Agents is a topic of significant interest and speculation in the field of artificial intelligence. These agents, powered by advanced language models, are expected to revolutionize various industries by enhancing human capabilities and solving complex problems.', 'research_steps': \"1. Conducted a specialized search on AI using the query 'future of LLM Agents'.\\n2. Performed a web search to gather general knowledge on the topic.\\n3. Filtered ArXiv papers to find relevant academic insights on multi-agent systems and planning while learning.\", 'main_body': 'LLM Agents are poised to become integral components of future AI systems, offering capabilities that extend beyond traditional software agents. These agents are designed to understand and generate human-like text, making them suitable for a wide range of applications, from customer service to complex decision-making processes. The development of LLM Agents is driven by the need to create systems that can learn and adapt in real-time, providing more personalized and efficient interactions.\\n\\nOne of the key areas of focus for the future of LLM Agents is their ability to work collaboratively in multi-agent environments. Research indicates that these agents can be programmed to achieve goals efficiently by learning from their environment and other agents. This capability is crucial for applications in fields such as logistics, healthcare, and finance, where multiple agents must coordinate to achieve optimal outcomes.\\n\\nMoreover, the integration of LLM Agents into existing systems is expected to enhance human capabilities by automating routine tasks and providing insights that were previously inaccessible. This transformation will likely lead to increased productivity and innovation across various sectors. However, the path to realizing the full potential of LLM Agents is fraught with challenges, including ethical considerations, data privacy, and the need for robust regulatory frameworks.', 'conclusion': 'The future of LLM Agents is promising, with the potential to transform industries and improve human-machine interactions. As these agents become more sophisticated, they will play a crucial role in addressing complex challenges and enhancing human capabilities. Continued research and development, along with careful consideration of ethical and regulatory issues, will be essential to harnessing the full potential of LLM Agents.', 'sources': \"1. ArXiv paper on multi-agent planning and learning (ArXiv ID: 9409101v1)\\n2. Medium article on the future of AI agents\\n3. Arcus blog on LLM-based agents\\n4. Foundation Capital's exploration of generative AI agents\"})\n",
            "\n",
            "        INTRODUCTION\n",
            "        ------------\n",
            "        The future of Large Language Model (LLM) Agents is a topic of significant interest and speculation in the field of artificial intelligence. These agents, powered by advanced language models, are expected to revolutionize various industries by enhancing human capabilities and solving complex problems.\n",
            "        \n",
            "        RESEARCH STEPS\n",
            "        --------------\n",
            "        1. Conducted a specialized search on AI using the query 'future of LLM Agents'.\n",
            "2. Performed a web search to gather general knowledge on the topic.\n",
            "3. Filtered ArXiv papers to find relevant academic insights on multi-agent systems and planning while learning.\n",
            "        \n",
            "        REPORT\n",
            "        ------\n",
            "        LLM Agents are poised to become integral components of future AI systems, offering capabilities that extend beyond traditional software agents. These agents are designed to understand and generate human-like text, making them suitable for a wide range of applications, from customer service to complex decision-making processes. The development of LLM Agents is driven by the need to create systems that can learn and adapt in real-time, providing more personalized and efficient interactions.\n",
            "\n",
            "One of the key areas of focus for the future of LLM Agents is their ability to work collaboratively in multi-agent environments. Research indicates that these agents can be programmed to achieve goals efficiently by learning from their environment and other agents. This capability is crucial for applications in fields such as logistics, healthcare, and finance, where multiple agents must coordinate to achieve optimal outcomes.\n",
            "\n",
            "Moreover, the integration of LLM Agents into existing systems is expected to enhance human capabilities by automating routine tasks and providing insights that were previously inaccessible. This transformation will likely lead to increased productivity and innovation across various sectors. However, the path to realizing the full potential of LLM Agents is fraught with challenges, including ethical considerations, data privacy, and the need for robust regulatory frameworks.\n",
            "        \n",
            "        CONCLUSION\n",
            "        ----------\n",
            "        The future of LLM Agents is promising, with the potential to transform industries and improve human-machine interactions. As these agents become more sophisticated, they will play a crucial role in addressing complex challenges and enhancing human capabilities. Continued research and development, along with careful consideration of ethical and regulatory issues, will be essential to harnessing the full potential of LLM Agents.\n",
            "        \n",
            "        SOURCES\n",
            "        -------\n",
            "        1. ArXiv paper on multi-agent planning and learning (ArXiv ID: 9409101v1)\n",
            "2. Medium article on the future of AI agents\n",
            "3. Arcus blog on LLM-based agents\n",
            "4. Foundation Capital's exploration of generative AI agents\n",
            "    \n"
          ]
        }
      ],
      "source": [
        "output = runnable.invoke({\n",
        "    'input': 'Create a summary about the future of LLM Agents.',\n",
        "    'chat_history': []\n",
        "})\n",
        "\n",
        "report = build_report(\n",
        "    output=output['intermediate_steps'][-1].tool_input\n",
        ")\n",
        "\n",
        "print(report)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1180d5b1-e62f-42b2-9040-24c49259b2f0",
      "metadata": {
        "id": "1180d5b1-e62f-42b2-9040-24c49259b2f0"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "589e6c67-e37d-4f4d-abe0-1dddebf6842f",
      "metadata": {
        "id": "589e6c67-e37d-4f4d-abe0-1dddebf6842f"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.4"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}